{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332220c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\esabh\\\\OneDrive\\\\Documents\\\\GitHub\\\\Follow-me-bot'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install ultralytics\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install torchaudio\n",
    "%pip install opencv-python\n",
    "%pip install timm\n",
    "%pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc03f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from deep_sort.utils.parser import get_config\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from deep_sort.sort.tracker import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a49db6a",
   "metadata": {},
   "source": [
    "### Human detection using YOLOv8\n",
    "To keep the computation real-time friendly, the lighter *YOLOv8s* variant is used but other variants can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 72.1M/131M [00:20<01:48, 566kB/s] "
     ]
    }
   ],
   "source": [
    "# Load a YOLOv8 model\n",
    "# YOLOv8 variants:\n",
    "# Top to Down: Small size, low accuracy -> Large size, high accuracy\n",
    "#     yolov8n.pt\n",
    "#     yolov8s.pt\n",
    "#     yolov8m.pt\n",
    "#     yolov8l.pt\n",
    "#     yolov8x.pt\n",
    "\n",
    "model = YOLO(\"yolov8l.pt\") # yolov8s.pt\n",
    "\n",
    "# Load a test image\n",
    "path = 'data/test_img.png'\n",
    "img = cv2.imread(path)\n",
    "\n",
    "# Detect person using YOLO\n",
    "results = model(img)\n",
    "\n",
    "# Display the results\n",
    "detect_img = results[0].plot()\n",
    "detect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(detect_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65ab1c",
   "metadata": {},
   "source": [
    "### Computing depth using MiDAS\n",
    "The smallest variant i.e., *MiDaS_small* is used here but other variants can also be used. The computed depth values are inversely proportional to the actual depth and have no units. During the first run, this will download the model weights and store it in cache, hence an internet connection is required to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c563889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\esabh/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\esabh/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\esabh/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "# Load MiDAS model\n",
    "# Different MiDAS models:\n",
    "# Top to Down: Large, more accuracy -> Small, less accurate\n",
    "#     \"DPT_Large\"\n",
    "#     \"DPT_Hybrid\"\n",
    "#     \"MiDaS_small\"\n",
    "\n",
    "model_type = \"MiDaS_small\"\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "\n",
    "# If GPU available, map MiDAS execution to GPU else CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "\n",
    "# Image transformation depending on MiDAS model type\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a106527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse the depth values from depth map\n",
    "def inverse_depth_value(depth_value, scale, constant=0):\n",
    "    return 1.0 / (constant + depth_value * scale)\n",
    "\n",
    "# Exponential moving average filter to smoothen depth values\n",
    "def apply_ema_filter(current_depth, alpha):\n",
    "    global previous_depth\n",
    "    filtered_depth = alpha * current_depth + (1 - alpha) * previous_depth\n",
    "    previous_depth = filtered_depth  # Update the previous depth value\n",
    "    return filtered_depth\n",
    "\n",
    "# Get depth map using MiDAS\n",
    "def get_depth_map(img):\n",
    "    input_batch = transform(img).to(device)\n",
    "    # Perform depth prediction using MiDAS\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    # Convert the depth map tensor to a NumPy array for plotting\n",
    "    depth_map = prediction.cpu().numpy()\n",
    "\n",
    "    return depth_map\n",
    "\n",
    "person_height = 1800 # in mm\n",
    "focal_length_sensor_height_ratio = 0.827433 # IPhone 14 Pro Max camera parameter\n",
    "\n",
    "def distance_to_object(real_object_height_mm, image_height_px, object_height_px):\n",
    "    # return focal_length_mm * real_object_height_mm * image_height_px/ (object_height_px * sensor_height_mm)\n",
    "    return focal_length_sensor_height_ratio * real_object_height_mm * image_height_px/ (object_height_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af48f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scale(img):\n",
    "    results = model(img, verbose=False)\n",
    "    # Get depth map\n",
    "    depth_map = get_depth_map(img)\n",
    "    # Get bounding box of all detected person\n",
    "    detected_objects = results[0].boxes.xyxy\n",
    "\n",
    "    max_area = 0\n",
    "\n",
    "    # For now this step iterates through all bounnding boxes, later we need to only use our locked bounding box\n",
    "    for obj in detected_objects:\n",
    "        x1, y1, x2, y2 = obj  # Extract bounding box coordinates\n",
    "        object_region_depths = depth_map[int(y1):int(y2), int(x1):int(x2)]  # Extract region from depth map\n",
    "        area = (x2-x1)*(y2-y1)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            # Calculate mean depth of bounded object\n",
    "            depth_value = np.mean(object_region_depths)\n",
    "            depth_in_mm = distance_to_object(person_height, img.shape[0], y2-y1)\n",
    "\n",
    "            # Find scale to convert depth value to distance\n",
    "            scale = 1 / (depth_value * depth_in_mm)\n",
    "    return scale\n",
    "\n",
    "def find_scale_and_constant(img1, img2):\n",
    "    midas_output = []\n",
    "    true_depth = []\n",
    "    for img in [img1, img2]:\n",
    "        results = model(img, verbose=False)\n",
    "        # Get depth map\n",
    "        depth_map = get_depth_map(img)\n",
    "        # Get bounding box of all detected person\n",
    "        detected_objects = results[0].boxes.xyxy\n",
    "\n",
    "        max_area = 0\n",
    "\n",
    "        # For now this step iterates through all bounnding boxes, later we need to only use our locked bounding box\n",
    "        for obj in detected_objects:\n",
    "            x1, y1, x2, y2 = obj  # Extract bounding box coordinates\n",
    "            object_region_depths = depth_map[int(y1):int(y2), int(x1):int(x2)]  # Extract region from depth map\n",
    "            area = (x2-x1)*(y2-y1)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                # Calculate mean depth of bounded object\n",
    "                depth_value = np.mean(object_region_depths)\n",
    "                depth_in_mm = distance_to_object(person_height, img.shape[0], y2-y1)\n",
    "        midas_output.append(depth_value)\n",
    "        true_depth.append(depth_in_mm)\n",
    "    scale = (1.0/true_depth[0] - 1.0/true_depth[1]) / (midas_output[0] - midas_output[1])\n",
    "    constant = 1.0/true_depth[0] - scale * midas_output[0]\n",
    "    return scale, constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9e37c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Depth Map')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run and view results from depth map function\n",
    "depth_map = get_depth_map(img)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(depth_map, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Depth Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b079128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = og_frame.copy()\n",
    "    classes = [0]   # Person class\n",
    "    result = model(frame, device=device, classes=classes)\n",
    "    \n",
    "    #depth_map = get_depth_map(frame)\n",
    "\n",
    "    boxes = result[0].boxes  # Boxes object for bbox outputs\n",
    "    probs = result[0].probs  # Class probabilities for classification outputs\n",
    "    cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "    conf = boxes.conf\n",
    "    xywh = boxes.xywh  # box with xywh format\n",
    "\n",
    "    pred_cls = np.array(cls)\n",
    "    conf = conf.detach().cpu().numpy()\n",
    "    bboxes_xywh = xywh\n",
    "    bboxes_xywh = xywh.cpu().numpy()\n",
    "    bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "\n",
    "    tracks = tracker.update(bboxes_xywh, conf, og_frame) # setting up the tracker\n",
    "\n",
    "    for track in tracker.tracker.tracks:\n",
    "        if(track.track_id == 1):\n",
    "            hits = track.hits\n",
    "            # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  \n",
    "            depth_in_mm = distance_to_object(person_height, frame.shape[0], y2-y1)\n",
    "            # Extract bounding box region from depth map\n",
    "            #object_region_depths = depth_map[int(y1):int(y2), int(x1):int(x2)]  \n",
    "            # Calculate mean depth of bounded object\n",
    "            # depth_value = np.mean(object_region_depths)  \n",
    "            # # Inverse the depth value\n",
    "            # depth_value = inverse_depth_value(depth_value, scale)\n",
    "            # depth_value = (apply_ema_filter(depth_value, alpha))\n",
    "            # Draw a rectangle and print depth value under the bounding box\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            depth_text = f\"{depth_in_mm:.2f}\"\n",
    "            cv2.putText(og_frame, depth_text, (int(x1), int(y2+25)), font, 1, (0,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return og_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 364.1ms\n",
      "Speed: 3.9ms preprocess, 364.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.8ms\n",
      "Speed: 2.0ms preprocess, 322.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.0ms\n",
      "Speed: 1.3ms preprocess, 322.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.5ms\n",
      "Speed: 2.1ms preprocess, 330.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.8ms\n",
      "Speed: 2.4ms preprocess, 323.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 2.5ms preprocess, 318.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.5ms\n",
      "Speed: 1.4ms preprocess, 323.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.3ms\n",
      "Speed: 1.4ms preprocess, 319.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.9ms\n",
      "Speed: 2.0ms preprocess, 323.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.9ms\n",
      "Speed: 1.2ms preprocess, 323.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.7ms\n",
      "Speed: 1.0ms preprocess, 318.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 1.5ms preprocess, 318.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.4ms\n",
      "Speed: 1.0ms preprocess, 319.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.6ms\n",
      "Speed: 2.0ms preprocess, 314.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.4ms\n",
      "Speed: 2.5ms preprocess, 315.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 332.2ms\n",
      "Speed: 2.2ms preprocess, 332.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 353.6ms\n",
      "Speed: 2.0ms preprocess, 353.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 344.0ms\n",
      "Speed: 2.3ms preprocess, 344.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.8ms\n",
      "Speed: 2.1ms preprocess, 326.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.6ms\n",
      "Speed: 2.0ms preprocess, 321.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 332.7ms\n",
      "Speed: 2.0ms preprocess, 332.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 329.2ms\n",
      "Speed: 1.0ms preprocess, 329.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 338.2ms\n",
      "Speed: 1.4ms preprocess, 338.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 327.4ms\n",
      "Speed: 5.9ms preprocess, 327.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.9ms\n",
      "Speed: 2.0ms preprocess, 322.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.7ms\n",
      "Speed: 1.5ms preprocess, 317.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.0ms\n",
      "Speed: 0.0ms preprocess, 312.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.2ms\n",
      "Speed: 3.0ms preprocess, 320.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.7ms\n",
      "Speed: 1.0ms preprocess, 321.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.9ms\n",
      "Speed: 2.5ms preprocess, 323.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 328.7ms\n",
      "Speed: 1.0ms preprocess, 328.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.9ms\n",
      "Speed: 2.0ms preprocess, 322.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.8ms\n",
      "Speed: 0.0ms preprocess, 324.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.9ms\n",
      "Speed: 1.5ms preprocess, 314.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.0ms\n",
      "Speed: 2.0ms preprocess, 316.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.1ms\n",
      "Speed: 2.0ms preprocess, 317.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 331.7ms\n",
      "Speed: 1.0ms preprocess, 331.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.6ms\n",
      "Speed: 2.1ms preprocess, 319.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.9ms\n",
      "Speed: 3.0ms preprocess, 313.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.4ms\n",
      "Speed: 1.2ms preprocess, 312.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 351.6ms\n",
      "Speed: 1.1ms preprocess, 351.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 356.3ms\n",
      "Speed: 2.1ms preprocess, 356.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.5ms\n",
      "Speed: 1.5ms preprocess, 324.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 329.3ms\n",
      "Speed: 2.2ms preprocess, 329.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.1ms\n",
      "Speed: 1.0ms preprocess, 315.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.2ms\n",
      "Speed: 1.0ms preprocess, 316.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 328.6ms\n",
      "Speed: 1.4ms preprocess, 328.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 349.0ms\n",
      "Speed: 1.0ms preprocess, 349.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.8ms\n",
      "Speed: 1.0ms preprocess, 326.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.3ms\n",
      "Speed: 1.1ms preprocess, 326.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.6ms\n",
      "Speed: 1.1ms preprocess, 315.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.7ms\n",
      "Speed: 2.3ms preprocess, 316.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.8ms\n",
      "Speed: 0.0ms preprocess, 309.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.8ms\n",
      "Speed: 3.9ms preprocess, 324.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.3ms\n",
      "Speed: 2.0ms preprocess, 317.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.0ms\n",
      "Speed: 2.0ms preprocess, 315.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 315.2ms\n",
      "Speed: 2.0ms preprocess, 315.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 312.8ms\n",
      "Speed: 1.2ms preprocess, 312.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 318.4ms\n",
      "Speed: 1.0ms preprocess, 318.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 314.0ms\n",
      "Speed: 3.0ms preprocess, 314.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 316.1ms\n",
      "Speed: 2.5ms preprocess, 316.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 311.4ms\n",
      "Speed: 1.1ms preprocess, 311.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.8ms\n",
      "Speed: 1.0ms preprocess, 313.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.5ms\n",
      "Speed: 2.0ms preprocess, 315.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.7ms\n",
      "Speed: 1.0ms preprocess, 315.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.4ms\n",
      "Speed: 1.4ms preprocess, 315.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.0ms\n",
      "Speed: 2.8ms preprocess, 310.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 312.4ms\n",
      "Speed: 2.0ms preprocess, 312.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 320.5ms\n",
      "Speed: 1.5ms preprocess, 320.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 316.0ms\n",
      "Speed: 1.0ms preprocess, 316.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.9ms\n",
      "Speed: 1.0ms preprocess, 314.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 312.4ms\n",
      "Speed: 10.7ms preprocess, 312.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.8ms\n",
      "Speed: 1.4ms preprocess, 315.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 335.8ms\n",
      "Speed: 2.0ms preprocess, 335.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.5ms\n",
      "Speed: 1.5ms preprocess, 313.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 328.0ms\n",
      "Speed: 2.1ms preprocess, 328.0ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 332.6ms\n",
      "Speed: 2.5ms preprocess, 332.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.4ms\n",
      "Speed: 2.3ms preprocess, 326.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.7ms\n",
      "Speed: 1.0ms preprocess, 312.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.9ms\n",
      "Speed: 3.0ms preprocess, 315.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 350.4ms\n",
      "Speed: 1.0ms preprocess, 350.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 350.9ms\n",
      "Speed: 1.3ms preprocess, 350.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.0ms\n",
      "Speed: 2.3ms preprocess, 316.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.8ms\n",
      "Speed: 2.1ms preprocess, 316.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.7ms\n",
      "Speed: 2.0ms preprocess, 321.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.0ms\n",
      "Speed: 1.0ms preprocess, 315.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.5ms\n",
      "Speed: 0.0ms preprocess, 323.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.0ms\n",
      "Speed: 0.0ms preprocess, 314.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.5ms\n",
      "Speed: 2.0ms preprocess, 314.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.5ms\n",
      "Speed: 2.6ms preprocess, 314.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.9ms\n",
      "Speed: 2.1ms preprocess, 311.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.5ms\n",
      "Speed: 2.1ms preprocess, 317.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.4ms\n",
      "Speed: 1.3ms preprocess, 312.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.6ms\n",
      "Speed: 5.5ms preprocess, 317.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.8ms\n",
      "Speed: 2.0ms preprocess, 314.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.9ms\n",
      "Speed: 9.8ms preprocess, 313.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.0ms\n",
      "Speed: 2.0ms preprocess, 314.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 307.2ms\n",
      "Speed: 2.0ms preprocess, 307.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.4ms\n",
      "Speed: 1.5ms preprocess, 311.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.5ms\n",
      "Speed: 2.0ms preprocess, 322.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.3ms\n",
      "Speed: 0.0ms preprocess, 315.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.2ms\n",
      "Speed: 1.0ms preprocess, 319.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.1ms\n",
      "Speed: 1.0ms preprocess, 315.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.8ms\n",
      "Speed: 1.5ms preprocess, 314.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.5ms\n",
      "Speed: 2.0ms preprocess, 317.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 331.6ms\n",
      "Speed: 2.2ms preprocess, 331.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.4ms\n",
      "Speed: 2.5ms preprocess, 317.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.1ms\n",
      "Speed: 2.5ms preprocess, 314.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.3ms\n",
      "Speed: 1.0ms preprocess, 313.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.3ms\n",
      "Speed: 2.4ms preprocess, 313.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.4ms\n",
      "Speed: 2.1ms preprocess, 312.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.0ms\n",
      "Speed: 2.0ms preprocess, 309.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.0ms\n",
      "Speed: 2.4ms preprocess, 315.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.2ms\n",
      "Speed: 2.2ms preprocess, 312.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.5ms\n",
      "Speed: 1.6ms preprocess, 309.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.2ms\n",
      "Speed: 2.0ms preprocess, 314.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.5ms\n",
      "Speed: 2.4ms preprocess, 309.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.6ms\n",
      "Speed: 2.6ms preprocess, 311.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.7ms\n",
      "Speed: 1.0ms preprocess, 312.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.1ms\n",
      "Speed: 1.0ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.2ms\n",
      "Speed: 1.0ms preprocess, 316.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.4ms\n",
      "Speed: 1.0ms preprocess, 310.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.2ms\n",
      "Speed: 1.0ms preprocess, 310.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.4ms\n",
      "Speed: 4.4ms preprocess, 313.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 309.9ms\n",
      "Speed: 1.0ms preprocess, 309.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.7ms\n",
      "Speed: 1.0ms preprocess, 314.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 316.0ms\n",
      "Speed: 2.5ms preprocess, 316.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.5ms\n",
      "Speed: 1.0ms preprocess, 310.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.9ms\n",
      "Speed: 2.0ms preprocess, 310.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 309.7ms\n",
      "Speed: 1.0ms preprocess, 309.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.0ms\n",
      "Speed: 3.0ms preprocess, 322.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.7ms\n",
      "Speed: 1.0ms preprocess, 314.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 312.0ms\n",
      "Speed: 2.2ms preprocess, 312.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.9ms\n",
      "Speed: 1.0ms preprocess, 315.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 308.2ms\n",
      "Speed: 2.0ms preprocess, 308.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.4ms\n",
      "Speed: 1.2ms preprocess, 314.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.6ms\n",
      "Speed: 1.9ms preprocess, 310.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 308.9ms\n",
      "Speed: 1.0ms preprocess, 308.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.4ms\n",
      "Speed: 2.5ms preprocess, 313.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.2ms\n",
      "Speed: 2.0ms preprocess, 310.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 309.9ms\n",
      "Speed: 1.4ms preprocess, 309.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 311.3ms\n",
      "Speed: 1.0ms preprocess, 311.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 311.2ms\n",
      "Speed: 0.0ms preprocess, 311.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 311.4ms\n",
      "Speed: 2.6ms preprocess, 311.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.8ms\n",
      "Speed: 1.1ms preprocess, 313.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.3ms\n",
      "Speed: 1.2ms preprocess, 315.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 323.6ms\n",
      "Speed: 2.2ms preprocess, 323.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.5ms\n",
      "Speed: 1.0ms preprocess, 314.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.4ms\n",
      "Speed: 1.0ms preprocess, 315.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 312.4ms\n",
      "Speed: 2.0ms preprocess, 312.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.4ms\n",
      "Speed: 2.0ms preprocess, 313.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.2ms\n",
      "Speed: 2.2ms preprocess, 315.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.6ms\n",
      "Speed: 2.0ms preprocess, 310.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 331.5ms\n",
      "Speed: 2.0ms preprocess, 331.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.6ms\n",
      "Speed: 2.0ms preprocess, 310.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 311.4ms\n",
      "Speed: 2.1ms preprocess, 311.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.6ms\n",
      "Speed: 1.0ms preprocess, 315.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 312.4ms\n",
      "Speed: 2.1ms preprocess, 312.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 314.4ms\n",
      "Speed: 2.1ms preprocess, 314.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 310.0ms\n",
      "Speed: 2.0ms preprocess, 310.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 317.1ms\n",
      "Speed: 2.1ms preprocess, 317.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.9ms\n",
      "Speed: 1.1ms preprocess, 322.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 331.3ms\n",
      "Speed: 1.4ms preprocess, 331.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.7ms\n",
      "Speed: 1.5ms preprocess, 315.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 309.9ms\n",
      "Speed: 2.0ms preprocess, 309.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 309.6ms\n",
      "Speed: 2.0ms preprocess, 309.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.0ms\n",
      "Speed: 2.2ms preprocess, 315.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 315.1ms\n",
      "Speed: 1.0ms preprocess, 315.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 311.2ms\n",
      "Speed: 1.1ms preprocess, 311.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 311.9ms\n",
      "Speed: 1.0ms preprocess, 311.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 309.3ms\n",
      "Speed: 2.0ms preprocess, 309.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 313.6ms\n",
      "Speed: 2.0ms preprocess, 313.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.5ms\n",
      "Speed: 1.5ms preprocess, 312.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.7ms\n",
      "Speed: 2.0ms preprocess, 313.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.9ms\n",
      "Speed: 1.4ms preprocess, 311.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 2.0ms preprocess, 318.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.8ms\n",
      "Speed: 2.4ms preprocess, 314.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.5ms\n",
      "Speed: 3.5ms preprocess, 315.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.3ms\n",
      "Speed: 1.0ms preprocess, 315.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.4ms\n",
      "Speed: 1.1ms preprocess, 312.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.1ms\n",
      "Speed: 1.4ms preprocess, 311.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.2ms\n",
      "Speed: 1.2ms preprocess, 310.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.2ms\n",
      "Speed: 2.5ms preprocess, 311.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.7ms\n",
      "Speed: 1.0ms preprocess, 312.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.8ms\n",
      "Speed: 1.5ms preprocess, 313.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.2ms\n",
      "Speed: 2.0ms preprocess, 310.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.8ms\n",
      "Speed: 2.0ms preprocess, 310.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.4ms\n",
      "Speed: 2.0ms preprocess, 317.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.1ms\n",
      "Speed: 2.3ms preprocess, 317.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.4ms\n",
      "Speed: 2.0ms preprocess, 311.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.9ms\n",
      "Speed: 2.0ms preprocess, 309.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.5ms\n",
      "Speed: 1.5ms preprocess, 309.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.0ms\n",
      "Speed: 2.2ms preprocess, 311.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.1ms\n",
      "Speed: 1.5ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 308.0ms\n",
      "Speed: 2.0ms preprocess, 308.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.2ms\n",
      "Speed: 1.1ms preprocess, 313.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.8ms\n",
      "Speed: 1.0ms preprocess, 311.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.9ms\n",
      "Speed: 2.0ms preprocess, 312.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.1ms\n",
      "Speed: 2.6ms preprocess, 313.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.4ms\n",
      "Speed: 2.0ms preprocess, 312.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.3ms\n",
      "Speed: 2.0ms preprocess, 315.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.4ms\n",
      "Speed: 2.2ms preprocess, 311.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.7ms\n",
      "Speed: 2.5ms preprocess, 330.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.5ms\n",
      "Speed: 2.0ms preprocess, 314.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.6ms\n",
      "Speed: 2.9ms preprocess, 312.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.8ms\n",
      "Speed: 2.0ms preprocess, 310.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.0ms\n",
      "Speed: 2.1ms preprocess, 317.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.1ms\n",
      "Speed: 2.1ms preprocess, 313.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.4ms\n",
      "Speed: 2.1ms preprocess, 319.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.4ms\n",
      "Speed: 1.0ms preprocess, 317.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.5ms\n",
      "Speed: 1.5ms preprocess, 315.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.7ms\n",
      "Speed: 1.0ms preprocess, 319.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.8ms\n",
      "Speed: 1.8ms preprocess, 319.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.1ms\n",
      "Speed: 1.0ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.9ms\n",
      "Speed: 2.0ms preprocess, 313.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.4ms\n",
      "Speed: 1.1ms preprocess, 311.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.1ms\n",
      "Speed: 2.3ms preprocess, 318.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.5ms\n",
      "Speed: 1.0ms preprocess, 315.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.7ms\n",
      "Speed: 1.0ms preprocess, 317.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.1ms\n",
      "Speed: 2.0ms preprocess, 316.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 346.3ms\n",
      "Speed: 2.0ms preprocess, 346.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 338.8ms\n",
      "Speed: 0.6ms preprocess, 338.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.0ms\n",
      "Speed: 1.3ms preprocess, 325.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 328.4ms\n",
      "Speed: 3.0ms preprocess, 328.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.1ms\n",
      "Speed: 2.0ms preprocess, 324.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.2ms\n",
      "Speed: 2.3ms preprocess, 318.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.8ms\n",
      "Speed: 1.3ms preprocess, 319.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 1.1ms preprocess, 318.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.5ms\n",
      "Speed: 2.0ms preprocess, 323.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.2ms\n",
      "Speed: 2.0ms preprocess, 317.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 339.4ms\n",
      "Speed: 2.6ms preprocess, 339.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 328.0ms\n",
      "Speed: 1.0ms preprocess, 328.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 338.9ms\n",
      "Speed: 2.0ms preprocess, 338.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 358.7ms\n",
      "Speed: 3.0ms preprocess, 358.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 650.6ms\n",
      "Speed: 2.5ms preprocess, 650.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 525.4ms\n",
      "Speed: 2.5ms preprocess, 525.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 414.5ms\n",
      "Speed: 1.5ms preprocess, 414.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 414.6ms\n",
      "Speed: 2.5ms preprocess, 414.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 416.9ms\n",
      "Speed: 2.0ms preprocess, 416.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 447.2ms\n",
      "Speed: 1.4ms preprocess, 447.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 428.9ms\n",
      "Speed: 2.0ms preprocess, 428.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 481.6ms\n",
      "Speed: 3.5ms preprocess, 481.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 449.2ms\n",
      "Speed: 2.0ms preprocess, 449.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 441.0ms\n",
      "Speed: 1.0ms preprocess, 441.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 381.8ms\n",
      "Speed: 2.3ms preprocess, 381.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 373.0ms\n",
      "Speed: 2.4ms preprocess, 373.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 423.2ms\n",
      "Speed: 2.0ms preprocess, 423.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 419.9ms\n",
      "Speed: 2.4ms preprocess, 419.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 410.3ms\n",
      "Speed: 2.0ms preprocess, 410.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.6ms\n",
      "Speed: 2.0ms preprocess, 321.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.2ms\n",
      "Speed: 1.0ms preprocess, 325.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.4ms\n",
      "Speed: 2.7ms preprocess, 317.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.4ms\n",
      "Speed: 1.0ms preprocess, 320.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 363.9ms\n",
      "Speed: 2.0ms preprocess, 363.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 349.6ms\n",
      "Speed: 2.0ms preprocess, 349.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.0ms\n",
      "Speed: 2.0ms preprocess, 320.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 374.8ms\n",
      "Speed: 0.0ms preprocess, 374.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 361.3ms\n",
      "Speed: 2.5ms preprocess, 361.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 376.0ms\n",
      "Speed: 1.9ms preprocess, 376.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 466.0ms\n",
      "Speed: 2.0ms preprocess, 466.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 420.2ms\n",
      "Speed: 2.0ms preprocess, 420.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 449.0ms\n",
      "Speed: 1.1ms preprocess, 449.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 419.4ms\n",
      "Speed: 2.4ms preprocess, 419.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 350.6ms\n",
      "Speed: 2.4ms preprocess, 350.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 402.5ms\n",
      "Speed: 3.0ms preprocess, 402.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 423.1ms\n",
      "Speed: 2.0ms preprocess, 423.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 452.9ms\n",
      "Speed: 1.0ms preprocess, 452.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 387.0ms\n",
      "Speed: 2.0ms preprocess, 387.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 431.7ms\n",
      "Speed: 2.0ms preprocess, 431.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 434.6ms\n",
      "Speed: 1.0ms preprocess, 434.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.6ms\n",
      "Speed: 2.0ms preprocess, 326.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.8ms\n",
      "Speed: 2.0ms preprocess, 320.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.9ms\n",
      "Speed: 2.0ms preprocess, 322.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.8ms\n",
      "Speed: 2.0ms preprocess, 319.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 370.9ms\n",
      "Speed: 2.3ms preprocess, 370.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 345.7ms\n",
      "Speed: 1.0ms preprocess, 345.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 1.0ms preprocess, 318.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.2ms\n",
      "Speed: 1.8ms preprocess, 321.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.0ms\n",
      "Speed: 2.1ms preprocess, 320.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.6ms\n",
      "Speed: 2.0ms preprocess, 319.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.4ms\n",
      "Speed: 1.0ms preprocess, 320.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.7ms\n",
      "Speed: 2.2ms preprocess, 320.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 1.5ms preprocess, 318.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.4ms\n",
      "Speed: 2.1ms preprocess, 323.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.2ms\n",
      "Speed: 2.4ms preprocess, 318.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.9ms\n",
      "Speed: 1.3ms preprocess, 320.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.6ms\n",
      "Speed: 2.0ms preprocess, 320.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.6ms\n",
      "Speed: 2.0ms preprocess, 320.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.8ms\n",
      "Speed: 2.2ms preprocess, 318.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.9ms\n",
      "Speed: 2.5ms preprocess, 318.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.2ms\n",
      "Speed: 2.0ms preprocess, 318.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.5ms\n",
      "Speed: 1.0ms preprocess, 321.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.3ms\n",
      "Speed: 3.0ms preprocess, 320.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 2.0ms preprocess, 318.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.0ms\n",
      "Speed: 1.0ms preprocess, 322.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.1ms\n",
      "Speed: 2.0ms preprocess, 320.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.8ms\n",
      "Speed: 1.0ms preprocess, 319.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.5ms\n",
      "Speed: 2.0ms preprocess, 322.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.4ms\n",
      "Speed: 2.2ms preprocess, 321.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 387.9ms\n",
      "Speed: 3.0ms preprocess, 387.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.9ms\n",
      "Speed: 1.1ms preprocess, 318.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run the algorithm for a video\n",
    "\n",
    "\n",
    "# Set input and output video path\n",
    "video_path = \"data/test_vid2.mp4\"\n",
    "output_path = \"data/output2.mp4\"\n",
    "\n",
    "# Load DeepSORT model\n",
    "deep_sort_weights = 'deep_sort/deep/checkpoint/ckpt.t7' #load the pretrained model\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=2000)\n",
    "classes = [0]  # Person\n",
    "class_name = 'person'\n",
    "\n",
    "# Get the video properties\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# Define the output format and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "# Initialise variables\n",
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()\n",
    "# Scale for depth inversion\n",
    "scale = 0.01 \n",
    "alpha = 0.2\n",
    "previous_depth = 0.0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Get and display depth from frame\n",
    "        og_frame = process_frame(frame)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
